{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930a6569",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_31608\\3586001306.py:26: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(path,options=option)\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver \n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from datetime import datetime\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "import random\n",
    "from bs4 import BeautifulSoup\n",
    "# from selenium.webdriver.common.proxy import Proxy, ProxyType\n",
    "from selenium.webdriver.support.ui import WebDriverWait  # for implicit and explict waits\n",
    "from selenium.webdriver.chrome.options import Options \n",
    "# db=firestore.client()\n",
    "\n",
    "\n",
    "def get_rand():\n",
    "    return random.uniform(2.0, 2.9)\n",
    "\n",
    "option = webdriver.ChromeOptions()\n",
    "option.add_argument('headless')\n",
    "# driver = webdriver.Chrome('path/to/chromedriver',options=option)\n",
    "\n",
    "website = 'https://www.facebook.com/ads/library/'\n",
    "# website = \"https://google.com\"\n",
    "path = 'F:\\company projects\\web_scapping\\webscrap\\chromedriver' \n",
    "\n",
    "# driver initialization \n",
    "driver = webdriver.Chrome(path,Options=option)\n",
    "# open Google Chrome with chromedriver\n",
    "driver.get(website)\n",
    "# time to wait(in sec) till page gets loaded \n",
    "time.sleep(get_rand())\n",
    "\n",
    "# selecting the country \n",
    "country = driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/div[1]/div/div/div/div[4]/div/div[2]/div/div/div/div[1]/div[2]/div/div[2]/div[1]/div[1]/div/div/div/div[1]/div[2]/div[1]/div/div/div') \n",
    "country.click()\n",
    "time.sleep(get_rand())\n",
    "search_country=driver.find_element(By.XPATH, '/html[1]/body[1]/div[1]/div[1]/div[1]/div[1]/div[1]/div[1]/div[4]/div[1]/div[2]/div[1]/div[1]/div[1]/div[1]/div[2]/div[1]/div[2]/div[1]/div[2]/div[1]/div[1]/div[1]/div[1]/div[1]/div[1]/div[1]/div[2]/div[2]/div[1]/label[1]/input[1]')\n",
    "search_country.click()\n",
    "time.sleep(get_rand())\n",
    "country=\"INDIA\"\n",
    "search_country.send_keys(country)\n",
    "time.sleep(get_rand())\n",
    "select_country=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/div[1]/div/div/div/div[4]/div/div[2]/div/div/div/div[1]/div[2]/div/div[2]/div[1]/div[2]/div/div/div[1]/div[1]/div/div/div[1]/div[2]/div[3]/div/div[2]/div[1]')\n",
    "select_country.click()\n",
    "time.sleep(get_rand())\n",
    "\n",
    "# selecting the ads type \n",
    "ads_type = driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/div[1]/div/div/div/div[4]/div/div[2]/div/div/div/div[1]/div[2]/div/div[2]/div[2]/div[1]/div/div/div/div[1]/div[2]/div[1]/div/div/div') \n",
    "ads_type.click()\n",
    "time.sleep(get_rand())\n",
    "all_ads=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/div[1]/div/div/div/div[4]/div/div[2]/div/div/div/div[1]/div[2]/div/div[2]/div[2]/div[2]/div/div/div[1]/div[1]/div/div/div[1]/div[2]/div/div[2]/div/div[2]/div[1]/div/div/div/div/div/div[1]')\n",
    "all_ads.click()\n",
    "time.sleep(get_rand())\n",
    "\n",
    "# Search specific key word\n",
    "Search_key=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/div[1]/div/div/div/div[4]/div/div[2]/div/div/div/div[1]/div[2]/div/div[2]/div[3]/div/div/div[1]/div/input')\n",
    "time.sleep(get_rand())\n",
    "search_keyword=\"wafer\"\n",
    "Search_key.send_keys(search_keyword)\n",
    "time.sleep(get_rand())\n",
    "Search_key.send_keys(Keys.ENTER)\n",
    "time.sleep(get_rand())\n",
    "\n",
    "# result_element=driver.find_element(By.CLASS_NAME, 'j1p9ls3c.gxngx1o2.mogvahtc.i6uybxyu.qc5lal2y.nnmaouwa.igjjae4c.aeinzg81')\n",
    "# result=int(((result_element.text).split(\" \")[0][1:]).replace(\",\",\"\"))\n",
    "\n",
    "for i in range(1,40):\n",
    "    driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")\n",
    "    time.sleep(10)\n",
    "\n",
    "    \n",
    "content = driver.find_elements(By.CLASS_NAME, '_99s5')\n",
    "time.sleep(10)\n",
    "\n",
    "print(len(content))\n",
    "# _9b9p _99s6- div class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1085127e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(content)\n",
    "scrapitem_list=[]\n",
    "i=0\n",
    "for elements in content:\n",
    "    try:\n",
    "    #     print(elements)\n",
    "        try:\n",
    "            obj_html_str = elements.get_attribute('innerHTML')\n",
    "        #     print(obj_html_str)\n",
    "            soup = BeautifulSoup(obj_html_str, \"html.parser\")\n",
    "        except:\n",
    "            print(\"HTML object or Soup error\")\n",
    "        try:\n",
    "            try:\n",
    "                ads_owner_idlink_full = soup.find(href=True)\n",
    "                ads_owner_idlink=ads_owner_idlink_full['href']\n",
    "            except:\n",
    "                print(\"link getting error\")\n",
    "            try:\n",
    "                data = elements.text.split('\\n')\n",
    "                sp_index = elements.text.split('\\n').index(\"Sponsored\")\n",
    "\n",
    "                ads_owner_name=data[int(sp_index)-1]\n",
    "            except:\n",
    "                print(\" data split error\")\n",
    "        \n",
    "            ads_status=data[0] \n",
    "    #         print(type(data[1]))\n",
    "            try:\n",
    "                \n",
    "                ads_date_full=data[1].split(\"-\")\n",
    "                \n",
    "                if len(ads_date_full)==1:\n",
    "                    \n",
    "                    ads_date=(ads_date_full[0])[19:]\n",
    "                   \n",
    "                else:\n",
    "                    ads_date=ads_date_full[0]\n",
    "            except:\n",
    "                print(\"ads_date error\")\n",
    "            \n",
    "            try:\n",
    "\n",
    "                if \"ID:\" in data[3]:\n",
    "                    ads_id=data[3][3:]\n",
    "                elif \"ID:\" in data[4]:\n",
    "                    ads_id=data[4][3:]\n",
    "                elif \"ID:\" in data[5]:\n",
    "                    ads_id=data[5][3:]\n",
    "                elif \"ID:\" in data[6]:\n",
    "                    ads_id=data[6][3:]\n",
    "                else:\n",
    "                    pass\n",
    "            except:\n",
    "                print(\"ID Error\")\n",
    "        except:\n",
    "            print(\"element error\")\n",
    "\n",
    "        d={\"ads_date\":str(ads_date),\n",
    "                \"ads_status\":str(ads_status),\n",
    "                \"ads_id\":int(ads_id),\n",
    "                \"ads_owner_name\":str(ads_owner_name),\n",
    "                \"ads_owner_idlink\":str(ads_owner_idlink)\n",
    "            }\n",
    "\n",
    "        scrapitem_list.append(d)\n",
    "    except:\n",
    "        print(i)\n",
    "        print(\"error in this iteration\")\n",
    "        break\n",
    "    i=i+1\n",
    "    \n",
    "    \n",
    "print(i)    \n",
    "print(scrapitem_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991b908b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " search_keyword_print=search_keyword\n",
    "with open('search_'+search_keyword_print+'.txt', 'w') as my_list_file:\n",
    " \n",
    "   #looping over the each ist element\n",
    " \n",
    "    for elements in scrapitem_list:\n",
    " \n",
    "         #writing to file line by line\n",
    " \n",
    "        my_list_file.write('%s\\n' % elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2ded3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import firebase_admin\n",
    "import requests\n",
    "import json\n",
    "\n",
    "from firebase_admin import credentials\n",
    "from firebase_admin import firestore\n",
    "\n",
    "\n",
    "# Setup\n",
    "def messaging(message):\n",
    "    serverToken = 'AAAA2lYEqXg:APA91bFVm5S5o7DY87Y1He-DAad4ePqOPQQttObJRkUbjogm1DJR7otEX6R0DBkBMVGnn7d7AvzVPl_R-S6SC1E3KMkzg0yHd6fDzNfb6QYzkMnoawhWxX4Alga_n_V07VCFOtwk-a4i'\n",
    "    deviceToken = 'cSdG7yJZIRTjiozIjAqxGX:APA91bHBeHuUOFNpa4syn7kAUVn23dvETRJNcxreGVUKMzQt5KP8Bk9zbXUd3lbZDltMKyy9eOOnp7LSwwDr9mJUPYdfKsHUS64PyCSp37rxZHn1KtJZahz0YwUNEbJi8H5_qUa4wTbB'\n",
    "\n",
    "    headers = {\n",
    "            'Content-Type': 'application/json',\n",
    "            'Authorization': 'key=' + serverToken,\n",
    "          }\n",
    "\n",
    "    body = {\n",
    "              'notification': {'title': 'New Record Found',\n",
    "                                'body': message\n",
    "                                },\n",
    "              'to':\n",
    "                  deviceToken,\n",
    "              'priority': 'high',\n",
    "            #   'data': dataPayLoad,\n",
    "            }\n",
    "    response = requests.post(\"https://fcm.googleapis.com/fcm/send\",headers = headers, data=json.dumps(body))\n",
    "    print(message,response.status_code)\n",
    "    print(response.json())\n",
    "    \n",
    "cred = credentials.Certificate(\"competitive-intelligence-4a07d-firebase-adminsdk-s6a5i-2a74042bdc.json\")\n",
    "\n",
    "try:\n",
    "    app = firebase_admin.initialize_app(cred)\n",
    "    db=firestore.client()\n",
    "except:\n",
    "    db=firestore.client()\n",
    "\n",
    "\n",
    "\n",
    "for batched_data in scrapitem_list:\n",
    "#     print(batched_data)\n",
    "    doc_id=str(batched_data[\"ads_id\"])\n",
    "    batch_status=str(batched_data[\"ads_status\"])\n",
    "    collection_name=str(search_keyword)\n",
    "    collection_ref = db.collection(collection_name)\n",
    "#     print(collection_ref)\n",
    "    col = collection_ref.get()\n",
    "#     print(col)\n",
    "    if len(col)==0:\n",
    "        doc_ref = db.collection(collection_name).document(doc_id)\n",
    "        doc_ref.set(batched_data)\n",
    "    else:\n",
    "        doc_ref = db.collection(collection_name).document(doc_id)\n",
    "        \n",
    "\n",
    "    doc = doc_ref.get()\n",
    "    if doc.exists:\n",
    "        doc_status=doc.to_dict()['ads_status']\n",
    "        if doc_status==\"Active\" and batch_status==\"Inactive\":\n",
    "            messaging(\"this ad is inactive now\")\n",
    "            doc_ref.update({\"ads_status\":\"Inactive\"})\n",
    "        elif doc_status==\"Inactive\" and batch_status==\"Active\":\n",
    "#             print(\"this ad is inactive now\")\n",
    "            messaging(\"this ad is Active now\")\n",
    "            doc_ref.update({\"ads_status\":\"Active\"})\n",
    "        elif doc_status==\"Inactive\" and batch_status==\"Active\":\n",
    "            print(\"this is still Inactive and in database\")\n",
    "        else:\n",
    "            print(\"this is still active and in database\")\n",
    "    else:\n",
    "        if batch_status==\"Inactive\":\n",
    "            print(\"ID NOT EXISTs----------this ad is inactived and not needed\")\n",
    "        else:\n",
    "            doc_ref.set(batched_data)\n",
    "            messaging(\"new ad is inserted\")\n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2baaf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa7357b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('websrapting_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "936f60b77e0c4a9559cf4182074e43b4d842001aaf86344fd0c21d10e864e1ea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
